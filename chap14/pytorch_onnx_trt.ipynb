{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_onnx_trt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b95f30ffb3cd4d1e8e5bdd8ce615b11e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c7006d6603ce4eeb8b3274882932a860",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7cf4cfdcc96e46af812caef6bd79ba62",
              "IPY_MODEL_2361640b29e243b28be94cb5815260e4"
            ]
          }
        },
        "c7006d6603ce4eeb8b3274882932a860": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7cf4cfdcc96e46af812caef6bd79ba62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f59335bcb6f4c37b84df47f5df217b1",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102502400,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102502400,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11a129d2d2c848068125b02dc50ee638"
          }
        },
        "2361640b29e243b28be94cb5815260e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_810c17c1ae974f309c2c73f4f997fb2d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:03&lt;00:00, 32.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c52eefcfb1714e7f8977cc89231599a8"
          }
        },
        "1f59335bcb6f4c37b84df47f5df217b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11a129d2d2c848068125b02dc50ee638": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "810c17c1ae974f309c2c73f4f997fb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c52eefcfb1714e7f8977cc89231599a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_otgh68H9f_0"
      },
      "source": [
        "# TensorRT with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p4ts4MW9fkt",
        "outputId": "cf78e935-ffbd-4612-bc41-a2f235929335"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May 12 00:25:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz6RrvTJ-LkT"
      },
      "source": [
        "## Download TensorRT7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ga7PWBJh9vWL",
        "outputId": "6875bd03-68c1-4e9c-ef49-517c8dc595d9"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=117bRc2ArDHFy9X0j5Y71pMn7q9Y777fH' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=117bRc2ArDHFy9X0j5Y71pMn7q9Y777fH\" -O TensorRT-7.2.3.4.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.1.tar.gz && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-12 00:27:51--  https://docs.google.com/uc?export=download&confirm=K_d1&id=117bRc2ArDHFy9X0j5Y71pMn7q9Y777fH\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.195.100, 74.125.195.139, 74.125.195.101, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.195.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-bc-docs.googleusercontent.com/docs/securesc/4mqm7oedsfn6qj87djsooo6flociam01/024c4ojllhmo5i1dfs5ogcks4790o3gf/1620779250000/08464293851449423376/07624238021879239110Z/117bRc2ArDHFy9X0j5Y71pMn7q9Y777fH?e=download [following]\n",
            "--2021-05-12 00:27:51--  https://doc-0o-bc-docs.googleusercontent.com/docs/securesc/4mqm7oedsfn6qj87djsooo6flociam01/024c4ojllhmo5i1dfs5ogcks4790o3gf/1620779250000/08464293851449423376/07624238021879239110Z/117bRc2ArDHFy9X0j5Y71pMn7q9Y777fH?e=download\n",
            "Resolving doc-0o-bc-docs.googleusercontent.com (doc-0o-bc-docs.googleusercontent.com)... 74.125.195.132, 2607:f8b0:400e:c09::84\n",
            "Connecting to doc-0o-bc-docs.googleusercontent.com (doc-0o-bc-docs.googleusercontent.com)|74.125.195.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=jq992s4f0n44i&continue=https://doc-0o-bc-docs.googleusercontent.com/docs/securesc/4mqm7oedsfn6qj87djsooo6flociam01/024c4ojllhmo5i1dfs5ogcks4790o3gf/1620779250000/08464293851449423376/07624238021879239110Z/117bRc2ArDHFy9X0j5Y71pMn7q9Y777fH?e%3Ddownload&hash=cigs9jfthnio11o1thsgq20c1ipbm6f3 [following]\n",
            "--2021-05-12 00:27:51--  https://docs.google.com/nonceSigner?nonce=jq992s4f0n44i&continue=https://doc-0o-bc-docs.googleusercontent.com/docs/securesc/4mqm7oedsfn6qj87djsooo6flociam01/024c4ojllhmo5i1dfs5ogcks4790o3gf/1620779250000/08464293851449423376/07624238021879239110Z/117bRc2ArDHFy9X0j5Y71pMn7q9Y777fH?e%3Ddownload&hash=cigs9jfthnio11o1thsgq20c1ipbm6f3\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.195.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-0o-bc-docs.googleusercontent.com/docs/securesc/4mqm7oedsfn6qj87djsooo6flociam01/024c4ojllhmo5i1dfs5ogcks4790o3gf/1620779250000/08464293851449423376/07624238021879239110Z/117bRc2ArDHFy9X0j5Y71pMn7q9Y777fH?e=download&nonce=jq992s4f0n44i&user=07624238021879239110Z&hash=svnlmvtf847bm427lug6s1hukrkfa1c4 [following]\n",
            "--2021-05-12 00:27:51--  https://doc-0o-bc-docs.googleusercontent.com/docs/securesc/4mqm7oedsfn6qj87djsooo6flociam01/024c4ojllhmo5i1dfs5ogcks4790o3gf/1620779250000/08464293851449423376/07624238021879239110Z/117bRc2ArDHFy9X0j5Y71pMn7q9Y777fH?e=download&nonce=jq992s4f0n44i&user=07624238021879239110Z&hash=svnlmvtf847bm427lug6s1hukrkfa1c4\n",
            "Connecting to doc-0o-bc-docs.googleusercontent.com (doc-0o-bc-docs.googleusercontent.com)|74.125.195.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘TensorRT-7.2.3.4.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.1.tar.gz’\n",
            "\n",
            "TensorRT-7.2.3.4.Ub     [   <=>              ] 973.35M  91.4MB/s    in 9.3s    \n",
            "\n",
            "2021-05-12 00:28:01 (105 MB/s) - ‘TensorRT-7.2.3.4.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.1.tar.gz’ saved [1020632285]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MdWlK2w-T71"
      },
      "source": [
        "## Install TensorRT7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQiKfYa99vYz"
      },
      "source": [
        "!tar -xvzf TensorRT-7.2.3.4.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.1.tar.gz\n",
        "!export TRT_LIBPATH=`pwd`/TensorRT-7.2.3.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoOZ_ToV9vbD",
        "outputId": "20c1f8d4-103a-48fc-e4b6-7a7fcb01ef91"
      },
      "source": [
        "%cd ./TensorRT-7.2.3.4/python/\n",
        "!pip install tensorrt-7.2.3.4-cp37-none-linux_x86_64.whl\n",
        "%cd ..\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TensorRT-7.2.3.4/python\n",
            "Processing ./tensorrt-7.2.3.4-cp37-none-linux_x86_64.whl\n",
            "Installing collected packages: tensorrt\n",
            "Successfully installed tensorrt-7.2.3.4\n",
            "/content/TensorRT-7.2.3.4\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-JstoUV9vdb",
        "outputId": "1af087dc-08ae-44ee-a37b-35dfc4097351"
      },
      "source": [
        "%cd ./TensorRT-7.2.3.4/onnx_graphsurgeon/\n",
        "!pip install onnx_graphsurgeon-0.2.6-py2.py3-none-any.whl\n",
        "%cd ..\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/TensorRT-7.2.3.4/onnx_graphsurgeon\n",
            "Processing ./onnx_graphsurgeon-0.2.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from onnx-graphsurgeon==0.2.6) (1.19.5)\n",
            "Collecting onnx\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/9b/54c950d3256e27f970a83cd0504efb183a24312702deed0179453316dbd0/onnx-1.9.0-cp37-cp37m-manylinux2010_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2MB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx->onnx-graphsurgeon==0.2.6) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx->onnx-graphsurgeon==0.2.6) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx->onnx-graphsurgeon==0.2.6) (3.12.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx->onnx-graphsurgeon==0.2.6) (56.1.0)\n",
            "Installing collected packages: onnx, onnx-graphsurgeon\n",
            "Successfully installed onnx-1.9.0 onnx-graphsurgeon-0.2.6\n",
            "/content/TensorRT-7.2.3.4\n",
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QHtIZJqBs56",
        "outputId": "e356d6cf-d6e9-4dbe-e1d9-b30dbc815aa3"
      },
      "source": [
        "!sudo apt-get install libnvinfer7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  cuda-nvrtc-11-1 libcublas-11-3\n",
            "The following NEW packages will be installed:\n",
            "  cuda-nvrtc-11-1 libcublas-11-3 libnvinfer7\n",
            "0 upgraded, 3 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 276 MB of archives.\n",
            "After this operation, 975 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-11-1 11.1.105-1 [11.1 MB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-11-3 11.4.2.10064-1 [134 MB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  libnvinfer7 7.2.3-1+cuda11.1 [131 MB]\n",
            "Fetched 276 MB in 6s (46.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package cuda-nvrtc-11-1.\n",
            "(Reading database ... 160706 files and directories currently installed.)\n",
            "Preparing to unpack .../cuda-nvrtc-11-1_11.1.105-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-11-1 (11.1.105-1) ...\n",
            "Selecting previously unselected package libcublas-11-3.\n",
            "Preparing to unpack .../libcublas-11-3_11.4.2.10064-1_amd64.deb ...\n",
            "Unpacking libcublas-11-3 (11.4.2.10064-1) ...\n",
            "Selecting previously unselected package libnvinfer7.\n",
            "Preparing to unpack .../libnvinfer7_7.2.3-1+cuda11.1_amd64.deb ...\n",
            "Unpacking libnvinfer7 (7.2.3-1+cuda11.1) ...\n",
            "Setting up libcublas-11-3 (11.4.2.10064-1) ...\n",
            "Setting up cuda-nvrtc-11-1 (11.1.105-1) ...\n",
            "Setting up libnvinfer7 (7.2.3-1+cuda11.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvjFZJU8-n0R"
      },
      "source": [
        "Add path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN43NmSI9vgD"
      },
      "source": [
        "!export PATH=$PATH:/usr/local/cuda/bin\n",
        "!export PATH=$PATH:/content/TensorRT-7.2.3.4/lib\n",
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64\n",
        "!export LIBRARY_PATH=$LIBRARY_PATH:/usr/local/cuda/lib64\n",
        "!source /etc/profile\n",
        "\n",
        "!export LD_LIBRARY_PATH=/content/TensorRT-7.2.3.4/lib:$LD_LIBRARY_PATH\n",
        "!source ~/.bashrc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chAq_9qj9vi1"
      },
      "source": [
        "# if neccessary, copy libs into /usr/lib/\n",
        "\n",
        "# !sudo cp -r /content/TensorRT-7.2.3.4/lib/ /usr/lib/\n",
        "!sudo cp /usr/local/cuda-11.1/lib64/libnvrtc.so.11.1  /usr/lib/\n",
        "!sudo cp /content/TensorRT-7.2.3.4/lib/libnvonnxparser.so.7  /usr/lib/\n",
        "!sudo cp /content/TensorRT-7.2.3.4/lib/libnvparsers.so.7  /usr/lib/\n",
        "!sudo cp /content/TensorRT-7.2.3.4/lib/libnvinfer_plugin.so.7  /usr/lib/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-y9kp_a_RLS",
        "outputId": "e7d5fb15-9b3f-4a19-dc9e-9469798e748d"
      },
      "source": [
        "!pip3 install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.1+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1MB 1.6MB/s eta 0:12:11tcmalloc: large alloc 1147494400 bytes == 0x56019120e000 @  0x7fbf26fe2615 0x560157b52cdc 0x560157c3252a 0x560157b55afd 0x560157c46fed 0x560157bc9988 0x560157bc44ae 0x560157b573ea 0x560157bc97f0 0x560157bc44ae 0x560157b573ea 0x560157bc632a 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157cca3e1 0x560157c2a6a9 0x560157b95cc4 0x560157b56559 0x560157bca4f8 0x560157b5730a 0x560157bc53b5 0x560157bc47ad 0x560157b573ea 0x560157bc53b5 0x560157b5730a 0x560157bc53b5\n",
            "\u001b[K     |█████████████████               | 1055.7MB 1.6MB/s eta 0:09:36tcmalloc: large alloc 1434370048 bytes == 0x5601d5864000 @  0x7fbf26fe2615 0x560157b52cdc 0x560157c3252a 0x560157b55afd 0x560157c46fed 0x560157bc9988 0x560157bc44ae 0x560157b573ea 0x560157bc97f0 0x560157bc44ae 0x560157b573ea 0x560157bc632a 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157cca3e1 0x560157c2a6a9 0x560157b95cc4 0x560157b56559 0x560157bca4f8 0x560157b5730a 0x560157bc53b5 0x560157bc47ad 0x560157b573ea 0x560157bc53b5 0x560157b5730a 0x560157bc53b5\n",
            "\u001b[K     |█████████████████████▋          | 1336.2MB 1.4MB/s eta 0:07:48tcmalloc: large alloc 1792966656 bytes == 0x56015a696000 @  0x7fbf26fe2615 0x560157b52cdc 0x560157c3252a 0x560157b55afd 0x560157c46fed 0x560157bc9988 0x560157bc44ae 0x560157b573ea 0x560157bc97f0 0x560157bc44ae 0x560157b573ea 0x560157bc632a 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157cca3e1 0x560157c2a6a9 0x560157b95cc4 0x560157b56559 0x560157bca4f8 0x560157b5730a 0x560157bc53b5 0x560157bc47ad 0x560157b573ea 0x560157bc53b5 0x560157b5730a 0x560157bc53b5\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1MB 1.6MB/s eta 0:03:05tcmalloc: large alloc 2241208320 bytes == 0x5601c547e000 @  0x7fbf26fe2615 0x560157b52cdc 0x560157c3252a 0x560157b55afd 0x560157c46fed 0x560157bc9988 0x560157bc44ae 0x560157b573ea 0x560157bc97f0 0x560157bc44ae 0x560157b573ea 0x560157bc632a 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157bc5853 0x560157c47e36 0x560157cca3e1 0x560157c2a6a9 0x560157b95cc4 0x560157b56559 0x560157bca4f8 0x560157b5730a 0x560157bc53b5 0x560157bc47ad 0x560157b573ea 0x560157bc53b5 0x560157b5730a 0x560157bc53b5\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 1.4MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0x56024ade0000 @  0x7fbf26fe11e7 0x560157b88f37 0x560157b52cdc 0x560157c3252a 0x560157b55afd 0x560157c46fed 0x560157bc9988 0x560157bc44ae 0x560157b573ea 0x560157bc560e 0x560157bc44ae 0x560157b573ea 0x560157bc560e 0x560157bc44ae 0x560157b573ea 0x560157bc560e 0x560157bc44ae 0x560157b573ea 0x560157bc560e 0x560157bc44ae 0x560157b573ea 0x560157bc560e 0x560157b5730a 0x560157bc560e 0x560157bc44ae 0x560157b573ea 0x560157bc632a 0x560157bc44ae 0x560157b573ea 0x560157bc632a 0x560157bc44ae\n",
            "tcmalloc: large alloc 2477727744 bytes == 0x5603354fc000 @  0x7fbf26fe2615 0x560157b52cdc 0x560157c3252a 0x560157b55afd 0x560157c46fed 0x560157bc9988 0x560157bc44ae 0x560157b573ea 0x560157bc560e 0x560157bc44ae 0x560157b573ea 0x560157bc560e 0x560157bc44ae 0x560157b573ea 0x560157bc560e 0x560157bc44ae 0x560157b573ea 0x560157bc560e 0x560157bc44ae 0x560157b573ea 0x560157bc560e 0x560157b5730a 0x560157bc560e 0x560157bc44ae 0x560157b573ea 0x560157bc632a 0x560157bc44ae 0x560157b573ea 0x560157bc632a 0x560157bc44ae 0x560157b57a81\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 6.9kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6MB 320kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: torchvision 0.9.1+cu101\n",
            "    Uninstalling torchvision-0.9.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.9.1+cu101\n",
            "Successfully installed torch-1.8.1+cu111 torchaudio-0.8.1 torchvision-0.9.1+cu111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MErxOBKm_Y2_",
        "outputId": "32a0885c-3e43-41ab-87aa-f08f855205c9"
      },
      "source": [
        "!pip install onnx onnxruntime pycuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Collecting pycuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/56/4682a5118a234d15aa1c8768a528aac4858c7b04d2674e18d586d3dfda04/pycuda-2021.1.tar.gz (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 7.3MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.12.4)\n",
            "Collecting mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/54/dbc07fbb20865d3b78fdb7cf7fa713e2cba4f87f71100074ef2dc9f9d1f7/Mako-1.1.4-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.5MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/5b/136e5688da9bbd915ee8190bfd6a007fc0b19d71f26d5a2ab4b737b2eeb4/pytools-2021.2.6.tar.gz (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx) (56.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (1.1.1)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2021.1-cp37-cp37m-linux_x86_64.whl size=627880 sha256=a3122be86817398d596b365099e883195d906b367cc4c263b8dca6afba3fa12c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/55/64/fd4dddcc5f1c25eebd90b5291c3769101dc978c70165685512\n",
            "Successfully built pycuda\n",
            "Building wheels for collected packages: pytools\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2021.2.6-py2.py3-none-any.whl size=60643 sha256=3e458d54c9ad0dc7b02f88b57d45684ec9c8cd255820861428d3f2a27587aaae\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/a6/65/447b9b4fd1d9bde84ad2fea2431a38f69f3fb573476a98ae03\n",
            "Successfully built pytools\n",
            "Installing collected packages: mako, pytools, pycuda\n",
            "Successfully installed mako-1.1.4 pycuda-2021.1 pytools-2021.2.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o186CR4x_s-i",
        "outputId": "d5fdeb0d-552c-427c-fb4d-c47151199072"
      },
      "source": [
        "# download image\n",
        "!mkdir ./data\n",
        "!wget  -O ./data/img0.JPG \"https://d17fnq9dkz9hgj.cloudfront.net/breed-uploads/2018/08/siberian-husky-detail.jpg?bust=1535566590&width=630\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-12 00:39:12--  https://d17fnq9dkz9hgj.cloudfront.net/breed-uploads/2018/08/siberian-husky-detail.jpg?bust=1535566590&width=630\n",
            "Resolving d17fnq9dkz9hgj.cloudfront.net (d17fnq9dkz9hgj.cloudfront.net)... 13.224.2.174, 13.224.2.116, 13.224.2.76, ...\n",
            "Connecting to d17fnq9dkz9hgj.cloudfront.net (d17fnq9dkz9hgj.cloudfront.net)|13.224.2.174|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 24112 (24K) [image/jpeg]\n",
            "Saving to: ‘./data/img0.JPG’\n",
            "\n",
            "\r./data/img0.JPG       0%[                    ]       0  --.-KB/s               \r./data/img0.JPG     100%[===================>]  23.55K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2021-05-12 00:39:12 (12.9 MB/s) - ‘./data/img0.JPG’ saved [24112/24112]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQYMuPDP_-Uc",
        "outputId": "bb21084d-5b08-42f2-d337-7d68f35265d7"
      },
      "source": [
        "# download imagenet class name(need for torch model)\n",
        "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-12 00:39:16--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10472 (10K) [text/plain]\n",
            "Saving to: ‘imagenet_classes.txt’\n",
            "\n",
            "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-12 00:39:16 (57.0 MB/s) - ‘imagenet_classes.txt’ saved [10472/10472]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "b95f30ffb3cd4d1e8e5bdd8ce615b11e",
            "c7006d6603ce4eeb8b3274882932a860",
            "7cf4cfdcc96e46af812caef6bd79ba62",
            "2361640b29e243b28be94cb5815260e4",
            "1f59335bcb6f4c37b84df47f5df217b1",
            "11a129d2d2c848068125b02dc50ee638",
            "810c17c1ae974f309c2c73f4f997fb2d",
            "c52eefcfb1714e7f8977cc89231599a8"
          ]
        },
        "id": "2gpkdJ1W_Y5j",
        "outputId": "373e22f4-32c3-4844-d2d9-4bcb2fb5b733"
      },
      "source": [
        "# load resnet50\n",
        "from torchvision import models\n",
        "model = models.resnet50(pretrained=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b95f30ffb3cd4d1e8e5bdd8ce615b11e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=102502400.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXl2IiU5_Y73"
      },
      "source": [
        "import cv2\n",
        "import torch\n",
        "from albumentations import Resize, Compose\n",
        "from albumentations.pytorch.transforms import  ToTensor\n",
        "from albumentations.augmentations.transforms import Normalize\n",
        " \n",
        "def preprocess_image(img_path):\n",
        "    # transformations for the input data\n",
        "    transforms = Compose([\n",
        "        Resize(224, 224, interpolation=cv2.INTER_NEAREST),\n",
        "        Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensor(),\n",
        "    ])\n",
        "\n",
        "     \n",
        "\n",
        "    # read input image\n",
        "\n",
        "    input_img = cv2.imread(img_path)\n",
        "\n",
        "    # do transformations\n",
        "\n",
        "    input_data = transforms(image=input_img)[\"image\"]\n",
        "    batch_data = torch.unsqueeze(input_data, 0)\n",
        "\n",
        "    return batch_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KExsr52O_Y_H"
      },
      "source": [
        "input = preprocess_image(\"./data/img0.JPG\").cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNq5VvPf_nmx"
      },
      "source": [
        "model.eval()\n",
        "model.cuda()\n",
        "output = model(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aADNoyJy_npG",
        "outputId": "808eb94d-0065-4c99-cf8c-c0e1623f472b"
      },
      "source": [
        "def postprocess(output_data):\n",
        "    # get class names\n",
        "    with open(\"imagenet_classes.txt\") as f:\n",
        "        classes = [line.strip() for line in f.readlines()]\n",
        "    # calculate human-readable value by softmax\n",
        "    confidences = torch.nn.functional.softmax(output_data, dim=1)[0] * 100\n",
        "    # find top predicted classes\n",
        "    _, indices = torch.sort(output_data, descending=True)\n",
        "    i = 0\n",
        "    # print the top classes predicted by the model\n",
        "\n",
        "    while confidences[indices[0][i]] > 0.5:\n",
        "        class_idx = indices[0][i]\n",
        "        print(\n",
        "            \"class:\",\n",
        "            classes[class_idx],\n",
        "            \", confidence:\",\n",
        "            confidences[class_idx].item(),\n",
        "            \"%, index:\",\n",
        "            class_idx.item(),\n",
        "        )\n",
        "        i += 1\n",
        "\n",
        "\n",
        "postprocess(output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "class: Eskimo dog , confidence: 45.000240325927734 %, index: 248\n",
            "class: Siberian husky , confidence: 44.0692138671875 %, index: 250\n",
            "class: malamute , confidence: 7.553358554840088 %, index: 249\n",
            "class: timber wolf , confidence: 2.859858512878418 %, index: 269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxMspbV3_nsh"
      },
      "source": [
        "# convert torch model to .onnx model\n",
        "ONNX_FILE_PATH = 'resnet50.onnx'\n",
        "torch.onnx.export(model, input, ONNX_FILE_PATH, input_names=['input'],\n",
        "                  output_names=['output'], export_params=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zcwPmgDAK5B"
      },
      "source": [
        "# load .onnx model\n",
        "import onnx\n",
        "onnx_model = onnx.load(ONNX_FILE_PATH)\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tk0BGL2DAK7g",
        "outputId": "d0018c10-c764-4d8a-f66a-2a48435b3b7a"
      },
      "source": [
        "# do inference with .onnx model(onnx default runtime) \n",
        "import onnxruntime\n",
        "import numpy as np\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"resnet50.onnx\")\n",
        "\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(input)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "np.testing.assert_allclose(to_numpy(output), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wslIa2kAK-4"
      },
      "source": [
        "# consstruct tensorRT inference model(engine)\n",
        "\n",
        "import tensorrt as trt\n",
        "\n",
        "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
        "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
        "def build_engine(onnx_path, shape = [1,224,224,3]):\n",
        "\n",
        "   \"\"\"\n",
        "   This is the function to create the TensorRT engine\n",
        "   Args:\n",
        "      onnx_path : Path to onnx_file. \n",
        "      shape : Shape of the input of the ONNX file. \n",
        "  \"\"\"\n",
        "   with trt.Builder(TRT_LOGGER) as builder, builder.create_network(1) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
        "       builder.max_workspace_size = (256 << 20)\n",
        "       with open(onnx_path, 'rb') as model:\n",
        "           parser.parse(model.read())\n",
        "       network.get_input(0).shape = shape\n",
        "       engine = builder.build_cuda_engine(network)\n",
        "       return engine\n",
        "\n",
        "def save_engine(engine, file_name):\n",
        "   buf = engine.serialize()\n",
        "   with open(file_name, 'wb') as f:\n",
        "       f.write(buf)\n",
        "def load_engine(trt_runtime, engine_path):\n",
        "   with open(engine_path, 'rb') as f:\n",
        "       engine_data = f.read()\n",
        "   engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
        "   return engine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp1O1HC1ALA4"
      },
      "source": [
        "import argparse\n",
        "from onnx import ModelProto\n",
        "import tensorrt as trt\n",
        "\n",
        "engine_name = \"resnet50.plan\"\n",
        "onnx_path = \"resnet50.onnx\"\n",
        "batch_size = 1 \n",
        "\n",
        "model = ModelProto()\n",
        "with open(onnx_path, \"rb\") as f:\n",
        "  model.ParseFromString(f.read())\n",
        "\n",
        "d0 = model.graph.input[0].type.tensor_type.shape.dim[1].dim_value\n",
        "d1 = model.graph.input[0].type.tensor_type.shape.dim[2].dim_value\n",
        "d2 = model.graph.input[0].type.tensor_type.shape.dim[3].dim_value\n",
        "shape = [batch_size , d0, d1 ,d2]\n",
        "engine = build_engine(onnx_path, shape= shape)\n",
        "save_engine(engine, engine_name) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XulQIdv6_nvM"
      },
      "source": [
        "import tensorrt as trt\n",
        "import pycuda.driver as cuda\n",
        "import numpy as np\n",
        "import pycuda.autoinit\n",
        "\n",
        "def allocate_buffers(engine, batch_size, data_type):\n",
        "\n",
        "   \"\"\"\n",
        "   This is the function to allocate buffers for input and output in the device\n",
        "   Args:\n",
        "      engine : The path to the TensorRT engine. \n",
        "      batch_size : The batch size for execution time.\n",
        "      data_type: The type of the data for input and output, for example trt.float32. \n",
        "   \n",
        "   Output:\n",
        "      h_input_1: Input in the host.\n",
        "      d_input_1: Input in the device. \n",
        "      h_output_1: Output in the host. \n",
        "      d_output_1: Output in the device. \n",
        "      stream: CUDA stream.\n",
        "\n",
        "   \"\"\"\n",
        "\n",
        "   # Determine dimensions and create page-locked memory buffers (which won't be swapped to disk) to hold host inputs/outputs.\n",
        "   h_input_1 = cuda.pagelocked_empty(batch_size * trt.volume(engine.get_binding_shape(0)), dtype=trt.nptype(data_type))\n",
        "   h_output = cuda.pagelocked_empty(batch_size * trt.volume(engine.get_binding_shape(1)), dtype=trt.nptype(data_type))\n",
        "   # Allocate device memory for inputs and outputs.\n",
        "   d_input_1 = cuda.mem_alloc(h_input_1.nbytes)\n",
        "\n",
        "   d_output = cuda.mem_alloc(h_output.nbytes)\n",
        "   # Create a stream in which to copy inputs/outputs and run inference.\n",
        "   stream = cuda.Stream()\n",
        "   return h_input_1, d_input_1, h_output, d_output, stream\n",
        "\n",
        "def load_images_to_buffer(pics, pagelocked_buffer):\n",
        "   preprocessed = np.asarray(pics).ravel()\n",
        "   np.copyto(pagelocked_buffer, preprocessed)\n",
        "\n",
        "def do_inference(engine, pics_1, h_input_1, d_input_1, h_output, d_output, stream, batch_size):\n",
        "   \"\"\"\n",
        "   This is the function to run the inference\n",
        "   Args:\n",
        "      engine : Path to the TensorRT engine \n",
        "      pics_1 : Input images to the model.  \n",
        "      h_input_1: Input in the host         \n",
        "      d_input_1: Input in the device \n",
        "      h_output_1: Output in the host \n",
        "      d_output_1: Output in the device \n",
        "      stream: CUDA stream\n",
        "      batch_size : Batch size for execution time\n",
        "      height: Height of the output image\n",
        "      width: Width of the output image\n",
        "   \n",
        "   Output:\n",
        "      The list of output images\n",
        "\n",
        "   \"\"\"\n",
        "\n",
        "   load_images_to_buffer(pics_1, h_input_1)\n",
        "\n",
        "   with engine.create_execution_context() as context:\n",
        "       # Transfer input data to the GPU.\n",
        "       cuda.memcpy_htod_async(d_input_1, h_input_1, stream)\n",
        "\n",
        "       # Run inference.\n",
        "\n",
        "       context.profiler = trt.Profiler()\n",
        "       context.execute(batch_size=1, bindings=[int(d_input_1), int(d_output)])\n",
        "\n",
        "       # Transfer predictions back from the GPU.\n",
        "       cuda.memcpy_dtoh_async(h_output, d_output, stream)\n",
        "       # Synchronize the stream\n",
        "       stream.synchronize()\n",
        "       # Return the host output.\n",
        "       out = h_output.reshape((batch_size,-1))\n",
        "       return out "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "JCn3VgOOAs-C",
        "outputId": "83637d5e-a248-4dc9-b961-8d28283bdbe5"
      },
      "source": [
        "# do inference with .onnx using TensorRT runtime\n",
        "import tensorrt as trt\n",
        "from PIL import Image\n",
        "import skimage.transform\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def rescale_image(image, output_shape, order=1):\n",
        "   image = skimage.transform.resize(image, output_shape,\n",
        "               order=order, preserve_range=True, mode='reflect')\n",
        "   return image\n",
        "\n",
        "input_file_path = './data/img0.JPG'\n",
        "onnx_file = \"resnet50.onnx\"\n",
        "serialized_plan_fp32 = \"./resnet50.plan\"\n",
        "\n",
        "im = preprocess_image(\"./data/img0.JPG\").cpu()\n",
        "\n",
        "engine = load_engine(trt_runtime, serialized_plan_fp32)\n",
        "h_input, d_input, h_output, d_output, stream = allocate_buffers(engine, 1, trt.float32)\n",
        "out = do_inference(engine, im, h_input, d_input, h_output, d_output, stream, 1)\n",
        "\n",
        "plt.title('inference logistic')\n",
        "plt.plot(out[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8bb58f0290>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEICAYAAABCnX+uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZgUxfnHv+/sLrvc54ooyAICKgooCIqoqKigJiYxJhpjjFHJgXd+GhSNJhrFaDQmHgkxajww3kcQUREQUUHuS0EBuY9d7muX3Z2p3x/dNVPd00f1TM/Ose/neXjY6emprr6+9dZbb71FQggwDMMw+Usk2xVgGIZh0oOFnGEYJs9hIWcYhslzWMgZhmHyHBZyhmGYPIeFnGEYJs9hIWdCgYiWEdEwzX17E9FCItpLRNdnuGoZgYimE9HVIZRzOxE9leJv9xFR93TrwOQ/xdmuAFMYCCH6BNj9VgDThBD9M1WffEEIcZ/OfkQ0HcALQoi46AshWmSqXkx+wRY5kw26AliWyg+JiI0PhrHBQs6EAhGtIaLh5t93E9ErRPSc6T5ZRkQDze+mAjgDwGOma6AXEZUS0UNEtI6IthLRP4ioqbn/MCLaQES/I6ItAJ4hoggRjSGiVUS03TxWO3P/CiISRHSFWd42Ihqr1LPIdGesMus2j4i6mN8dRUQfEtEOIlpBRD/SPPcIEd1BRGuJqNI879bK9z8zv9tORHc6XKsXzL/LiOgFc79dRDSHiDoS0Z8AnKpcs8fM/QURHWn+3ZSI/mIeZzcRzZTXkCl8WMiZTPFdAP8F0AbAOwAeAwAhxJkAPgFwrRCihRDiawDjAPQC0B/AkQAOB/B7paxDAbSDYcmPAnAdgO8BOB3AYQB2AnjcdvyhAHoDOAvA74noaHP7zQAuBXAegFYAfgHgABE1B/AhgAkADgFwCYAniOgYjXP9ufnvDADdAbSQ52v+/gkAlwHoBKC1eX5OXGF+3wVAewC/AlAthBgL6zW71uG3DwEYAGAIjGt1K4CYRt2ZAoCFnMkUM4UQk4QQUQDPA+jntBMREQxxvkkIsUMIsRfAfTCEVBIDcJcQ4qAQohqGwI0VQmwQQhwEcDeAH9rcLn8QQlQLIRYBWKQc/2oAdwghVgiDRUKI7QAuALBGCPGMEKJeCLEAwOsALtY418sAPCyEWC2E2AfgNgCXmPX5IYD/CSFmCiFqYTRQbgmO6mAI+JFCiKgQYp4QYo/fwYkoAqNBukEIsdH87WfmtWEaAexvZDLFFuXvAwDKiKhYCFFv268cQDMA8wxNBwAQgCJlnyohRI3yuSuAN4lItTijADp6HF8ODHYBsMqhvl0BDCaiXcq2YhiNkB+HAVirfF5r/raj+d16+YUQ4gARbXcp53mzfv8lojYAXoDRYNX5HL8DgDI4nxfTCGCLnMk22wBUA+gjhGhj/mtti8iwW7DrAYxU9m8jhCgTQmzUON56AD1ctn9sK7OFEOLXGmVugtEQSI4AUA9gK4DNADrLL0y/dXunQoQQdUKIPwghjoHhIrkAwM/k1x7H3wagxuW8mEYACzmTVYQQMQD/AvAIER0CAER0OBGd6/GzfwD4ExF1NfcvJ6ILNQ/5FIB7iKgnGfQlovYAJgLoRUSXE1GJ+e9ExbfuxUsAbiKibkTUAoZr6GWz9/EagO8Q0RAiagLDDUROhRDRGUR0HBEVAdgDw9Uiex1bYfjfkzCv4dMAHiaiw8wB3ZOJqFTzmjB5Dgs5kwv8DsBKALOIaA+AKTAGKt14FMYA6gdEtBfALACDNY/1MIBXAHwAQyz/DaCp6Zs/B4ZvfhMM18wDAHTE8GkYbpEZAL6FYR1fBwBCiGXm3/+FYZ3vA1AJwMl/fSgM4d8D4CsAHyPh2nkUxjjATiL6m8Nv/w/AEgBzAOww687vdyOBeGEJhmk4TIt9F4CeQohvs10fpjDgFpthMgwRfYeImpkhjg/BsJzXZLdWTCHBQs4wmedCGO6aTQB6ArhEcFeYCRF2rTAMw+Q5bJEzDMPkOVmZENShQwdRUVGRjUMzDMPkLfPmzdsmhCi3b8+KkFdUVGDu3LnZODTDMEzeQkRrnbaza4VhGCbPYSFnGIbJc1jIGYZh8hwWcoZhmDyHhZxhGCbPYSFnGIbJc1jIGYZh8hwW8gJm4uJN+HyV22I0DMMUCrzUW4FSUxfFtRMWAABm334WOrYqy3KNGIbJFGyRNwL2HbQvk8kwTCHBQt4IKI44rizGMEyBwELeCChiIWeYgoaFvEBR08wXR/g2M0whw294gSKQUHI2yBmmsGEhZxiGyXNYyAsU1bXCi/kxTGGjLeRE9DQRVRLRUmXb3US0kYgWmv/Oy0w1maCo4s3LsjJMYRPEIn8WwAiH7Y8IIfqb/yaFUy0mXXhRbYZpPGgLuRBiBoAdGawLkyEEO1cYpqAJw0d+LREtNl0vbd12IqJRRDSXiOZWVVWFcFjGC5Zuhmk8pCvkTwLoAaA/gM0A/uK2oxBivBBioBBiYHl50iLQTMhYBjtZ1RmmoElLyIUQW4UQUSFEDMC/AAwKp1pM2nDUCsM0GtISciLqpHz8PoClbvsyDMMwmUE7jS0RvQRgGIAORLQBwF0AhhFRfxhG3xoAv8xAHZkUUAc4OYKFYQobbSEXQlzqsPnfIdaFCRH2kTNM44FndjIMw+Q5LOQFChvhDNN4YCEvUNgvzjCNBxbyAoVzrTBM44GFvBHAU/QZprBhIS9Q2ApnmMYDC3mBYo0jz2JFGIbJOCzkhQqLN8M0GljIGwF2Ta/cU4Ovt+7NSl0Yhgkf7ZmdTH5hjVqxSvmQcVNRHxNYM+78hq0UwzAZgS3yAsXLL14fY78LwxQSLOQFimWwM4v1YBgm87CQMwzD5Dks5AUKZz9kmMYDC3mBIjw+MQxTWLCQMwzD5Dks5AWKGnLIrhWGKWxYyAsUFm+GaTywkDcCWNMZprBhIW8EsHXOMIUNC3mBwuLNMI0HFvICxTqzk1WdYQoZFvICRccij3HOFYYpCFjIGwFuoh5j/wvDFAQs5AWKzuLLURZyhikIWMgLFHsOcud9GqAiDMNkHBbyRoDbYGeUfeQMUxCwkBcoOhLNPnKGKQxYyAsUnTS2sVjD1IVhmMzCQl6w+FvbPNjJMIUBC3kjhl0rDFMYsJAXKHquFRZyhikEWMgLFEscuYubhXWcYQoDFvICRcdrwj5yhikMWMgbAexaYZjChoW8QNHJeMiDnQxTGLCQFyiWwU6XfXhmJ8MUBizkWebdxZtxy6uLQi/XGrXCg50MU8iwkGeZ0RPm49V5G7JybHatMExhoC3kRPQ0EVUS0VJlWzsi+pCIvjH/b5uZajJBsa4Q5Ex9lIWcYQqBIBb5swBG2LaNAfCREKIngI/Mz0wO4GVstygtBgDsqq5toNowDJNJtIVcCDEDwA7b5gsB/Mf8+z8AvhdSvZgQsYt6ectSAEDV3oNZqA3DMGGTro+8oxBis/n3FgAd3XYkolFENJeI5lZVVaV5WCYYViUvb2EIeeUeFnKGKQRCG+wURmiEa4deCDFeCDFQCDGwvLw8rMMyLni6VsoM18remroGqk1h8s3WvXwNmZwgXSHfSkSdAMD8vzL9KjFhYBnsdBH16rpoA9WmMDn7kRn46b+/yHY1GCZtIX8HwBXm31cAeDvN8pgGhIU8fRat35XtKjBMoPDDlwB8DqA3EW0goqsAjANwNhF9A2C4+ZnJAbxmdsoJQtW1vEQQwxQCxbo7CiEudfnqrJDqwoSIJY2tq2ulvkHqwjBMZuGZnQWK27R8ICHy1bXsWmGYQoCFvBFgF3X5cdqKKtSwn5xh8h4W8gJFd/L9rgMcPscw+Q4LeYHiOdhp+ZvzrTBMvsNC3gjwmhzEOclTw2sMgmEaGhbygsVjsFP4TxZivOHrxuQSLOQFitW14q46bJGnBl81JpdgIS9QdIWGF5dIDXatMLkEC3ljwENzWMgZJv9hIS9QvKfoJ/5mz0pq8GVjcgkW8hwh7K66bnnsI08N7sgwuQQLeY4QtjB45VpRBz/ZtZIaHH/P5BIs5DlCQ8qCxbXCCRAZJu9hIc8RwnetKH97hR+yRZ4SfNmYXIKFPEcIWxe8VgiyDnayIjFMvsNCniOErqea5cV4sDMluP1jcgkW8hwhjMGzLbtrHNPSJifNUgc70z5so4QHO5lcgoU8RwjDwjvp/o/wmxfnG+Vp/obDDxkm/2EhLzCmLq8EYBvsdFlYwuk7Rg++bEwuwUKeI6QrDDpLu6kURQgAR62kCl81JpdgIS8QvCb9JO0LoIgMIWfPSmpwT4bJJVjIc4R0B8+88qk4FR0x7zxHraQGXzUml2AhzxHSNfDs8eCey7kJ1SJnSWKYfIeFPEdIV06D6nFE+sjZIk8Jbv+YXIKFPEdI1+eaZJF7LOcmIOKDnbsO1GF11b60jt0oYSFncojibFeAMQjbIvcqTwig2BTyW19fDABYM+78NGvQuOAJQUwuwRZ5jpB2+KGDH9yr7IjpI2cYJv9hIc8V0h7s1C9aIBFHzqQG+8iZXIKFPEdIO/wwKWrFuzy2yNODdZzJJVjIc4T0ww/dy0ueoi/YIk8TnhDE5BIs5DlC+oOdwUqwCzkLUzD4ajG5BAt5jpCukHotHuHkI7cb5BxPzjD5Cwt5jpCujHrO7HQo3G6R17OQB4I7MEwuwUKeI6QffmgvzyNplkge7GSLPBgcR87kEizkOUK6wuCdMyX5O7bI04QvF5NDsJAXCIFmdiJZyNkiZ5j8hYU8V0h7YQn3z0nGukP4YX0sll4FGhnc7DG5BAt5jhD2YKdaouMKQTYfeX2UpSkIPNjJ5BKhCDkRrSGiJUS0kIjmhlFmYyPswU6/fSM2i3zaikpc+NhM1EfZMteBBzuZXCJMi/wMIUR/IcTAEMtsNPx96jdp/d6+0o+nawXJFvnYN5di0Ybd2L6/Nq16NBbYImdyCXat5Agvzl6X1u+DprF1m6LPOVgYJv8IS8gFgA+IaB4RjXLagYhGEdFcIppbVVUV0mHzm9mrt3t+H40JvL1wo9a6mvauvnVmp/Fh5/7aeHSK3bUiYR3Xgw1yJpcIS8iHCiFOADASwGgiOs2+gxBivBBioBBiYHl5eUiHzV/WbT+AH4+f5bnPc5+vwQ3/XYhX5q73LS8paZY62CmA3dV1OP6eD/HA5OXGCkEugs2LMevBuWmYXCIUIRdCbDT/rwTwJoBBYZRbyOw9WOe7z5bdNQCAnQfc991/sB6xmEgSFjUuPCYE3l+6BQAwaclmAO4ulCgLlBZ8mZhcIm0hJ6LmRNRS/g3gHABL0y230CH4+zDkbMtiFzdITV0Ufe56H+MmL0+yyNVwxBdnrYsv6QYkRMipWJ4YxDD5RxgWeUcAM4loEYAvALwrhJgcQrkFjY4v2s+fLSNM3lm4KckiV+f3rNtxIOm4RM4DnjwviGHyj7QXXxZCrAbQL4S6NCp0hFxa1W7+7P0H6wEAzUqLkgbfVBdJcu5x43/DvWJzybDPQAu+TEwuweGHWSKIa6WoyPk2PTrFiD1vWVqcNLNTHbQstrUEwqyBk5+cXSt68IQgJpdgIc8SOiutRaPePvJ3zYHL5qXFSRaim0UuGxBX1wqbmlrwZWJyCRbyLKGjA9G4a8Vb9T9btR3VdVHLNtWwtjcE0p/uVCxb5IXHjv21WLNtf7arwWQQFvIsoWP5SveIzkLJG3ZWx/8+UFuPu95OBA4VRZJvM7mUy0KuR9CrtG3fwYzUQ4ehD0zFsIemZ+34TOZhIc8SOoJZH0DI1aiVZz5d42qRq1a4k4+cXSt6BJkQ9Nq8DRh47xQs3rArgzVy50Bt1H8nJq9hIc8SOjoQDSDkTr+TOIUvEjkLOVvkegS5Sp+t2gYA+HrrvsxUhmn0sJBnCT/B3LirOj6Y6TbYqcui9QlLkOA9IYgtcj0CXSa+pEyGYSHPEn6COW/tzvjfOjHnN/x3odZxySyMQC4+cq1imBR46pPVqBjzrmcjPmv1dlSMeRdb99Q0YM2YfIeFPEv4CbmqsUG9HX66L2OgnVwrvOSbLsHN7OVb9gIAauvdr/FLXxjpjD9duS21ajGNEhbyLOEnzuqEISfRTzf7HhHgEMyCp2euwegX56dVdmMgncvvNXu2ddMSAMCeav+kakwwet/xHi58/NNsVyMjpD1FnwG+3roXTUuK0KVdM+3f+PnI/SzyVMckrT7yZIt8yldbAQCPa5a3t6YOAkCrspLUKpSnpNOMei2nJ4V8d3V9GkdgnDhYH7OMFxUSbJGHwDmPzMCpf54W6Dd+rhVSRNbJ+vb6vY7IEPlPNNLhuLs/QN+7P0i7nEwy5cutWFkZbsRIEIvcvmudx0LXUsh3VfOSe4Bh8GzaVe2/YyOHhTxL+LmiVYvcSTTSiS6Rv2wsqwFd/dxcDH/4Y9/91mzb3yALRriNQwx9YCruffcrAIb1yAAPfbACQ8ZNjefmZ5xhIc8SQSxyZx+5x289CzYsfLeolcbKsk27Meyh6Xjqk2+19k8naVa9i0Wuzs7lKFCDGV8by0Jmc2asG8/PWou123Mj9QELeZbwSxfrZ5Gn/aK7TAhqrEgR/WLNDq3907n+dRoxnvaewdkPf4yxby5J/aCNiM9WbsN6JQd/Jqipi+LOt5biR//8PKPH0YWFPEv4deEjPhZ5GK4VFvIEcrxAd83SQD5y2871Ootp23b5pnIfXpy9Tv+gjZifPDU78JhVqngtw9iQsJBnCT+jjDLkIyflf3atJJChmA2xsIaORZ7K/Z28dDOq9uaeC6IQybUZ0CzkCvXRWEZyjWzZXWOZqQkEexAcfeQe+/sa2h5T9CXPf77Gp5DCQvZOdO9/JnzkKl7VEELg3olf4iMzVBQwuvq/emE+fvrU7JTqNHv1dtTYUiEv27Qb75lpIvzYtKsaN728MKmMsMi0bm7YeQDvLNqkvX8qMrH7QB2Wbtwd/IcasJArHDn2PYx8dEbo5Z798Me46MnPLNv8uvDqg+u0p0gzqIGIXNcCBYA7316GrzbvSe8gJiu27E05GiQaExmLJFHLlb2TumgMn2nMqkynSjqzZ73OefmWvXhq5rf406Sv4ttkY78mhcG3ddsP4MfjZ+F2mw/+/L/NxK81J4fd9c4yvLlgI6avqPLcLxYTmLaiUvueNpT376InP8P1Ly3QrlcqBt8l/5qFC/4+M/DvdGAht5GJDHV7D1ond2zcVe3boqsPSpg+8lVV+7HaXGTAz0eu4wLwY+ybS3DuX2fgtXkbUvp9j9snYexbS/13DMiqqn3odtskvDp3PYDEtZi1egd+8tRszFq9PZTjbNpVjanLKy3bvOLIJV57yLVaD9Yl7o98XoIKzKcrt+G0Bw1/8gozhUAqyMfxFfN6uvH0p9/iymfmYPLSLZi2vDIpXcGemjo8P2sthBBYvmUPlm70Nib21NRh/rpEb1d3jMPO1j2GS0r353HBD3C4sAwjJ1jIG5Ad+2txz8Qvccq4qbjjLe8IBFWonWd2Oj9Bun5vQjgTgrz4ctOe+ACdm6U4e/V2/Humc8iffFkmhDzIV1MXxVl/MeLK/7fYcB3YGzWvpFW19TFtX/QFf5+JPTXWhlzPteK+T63ZwKprsUojP6iPX21gwxj8nrq8Equq3I0hGU0ycclmXPnsHPx58nLL92PfXIo731qKeWt3YsRfP/E93tXPzsUPnvgMB+sNl05dmrmCdHMN6TaYSzfuTprQlIkeJk/Rb0Cu+s8cLFhnTBH2G+22vMiOFrnz74KkvA363p75l+k49rDWGHVad9THBNo3b+K5/4HahIDJGYt2fjx+FgDgqqHdkr7Tie5wIxYTWFW1Dz07tkz6Tp1s06ykCEDytfB6UW98eQEmLdmiVY8d+5NnaOqIjde7Li16tdGWz0tQjVBFJb2x70Q52/fVoke5815yfsR2My58rS1MsGqv0YDWOvQGq2ujOPr3k3HH+Ufj6lO7AwAWmYt1yNPQaSSd62WUodsO6PYwpStlzbjz49tiAigK2YZii7wBCTJNXNURJ01xG2zTFXK3xZedkC/76qr9eGfRJlzw95n43uOf+oZ4qT74+yYtR2XA1KzpuHaemL4SZz8yA8s2JQ8uqafdrIkh5HYL2EvIdUXcjXQt8jqzIVLvtY4lfsdbS5ImsKinSSH10LZrTN6R1bUfUQqpvXcgILDjgNEoPu3Qg0tFyD9YtiXu2pHH07XI739vebxeQclExAsLeQMS5CGz+8jXbt+Pf8/8Nr7d7VkIElKo05XeW1OHbrdNwn8+W6NdrsTeqLz/5VaXPZ2pqxeO5bhRWx+L+0hlz2fTruTGQ710TU0ht1/PVAazqmujWr51r6RZEq93XYqNuharjm/4hVnrcL0tb736q3QscrW+e2r8Y6vjQm7vCZlf2LM/XjthAf41Y7VRT4eKSkF1suSdmL16O0Y9Py/u2pElnvvIjPi4iWTOmh2+0Ti7q+u03W2ZiIxjIW9A/Fr7iYs3xa1ftdUWAvjHx6twz8QvMeObqqTvVYqL9G4pwfmFUBHC8HMDwBsLNmqVqxLE57po/S789pVFFkE6GDVeHp3GKRYT6HXHe/jjxC8BeLuN1EsnLXL7y5VKPPnYN5fgkvGzsG6796xCnbK9feTGdyVFwSxyINkCVl0rOhZ55Z4aVIx5F28vtD4P6tF1tFTWl2w1kvdh1PPzLNvX7TiAZ01jQk1lIJG3T9ei3muOW9gH/jftrsEtry2O77e6ah8u/sfn+MP/lsW3Ofm4hz/8MU780xStY7NFnuO4JfaR74dftMK1Exbg05WGRWcd7BTxBXQ3mxamW6OuPdhJpGWBbdptvDRHaKToramLYopidTtZHvPW7sQT01cmbb/y2Tl4ff4G7DyQ8CnXxQXL/zGVfufnZ621bHd66dRtTUucXSupRD/IhSP8LFJ5XSYu3oRql4WRPX3kTq4Vzfra77l6nAgB495bjk9XbksaoJu/bqcp4EastVwAI1FOoqCog5hW10Yt+8h5Ffa2Q1fkNu6qxsrKvfHxDvk72YvzomLMu/EB9rj7zuVd2GdGCKnRM04JzYJMxGKLPMd59KOvHbfrCJFksymc6rsgBNC2mTGwKJMHuY18FxFph1DpRK3Iw+gMzlw7YT6ufm4uNpoi4DRYedGTn+HPk1c4HCd537hgaRxcuq2SfK6OET+Jv5sUR8xt1h3VulfXRrVCx6SnQ5blFs4XjQksWr8L105YgN+/bYRW2s/f00cuo1YsrhXf6hl1tN1z9TgEwj8+XoXLnpqNIeOmxre/Mmc9rpuwAADwqbmQtP26qh/ltauLxlC5pwb10Rj6/fEDjJ4wP0m431u6xXJtdYV814FaDH84MedDzqtQB5IfsEXEqHxuusDkc+Nm1EjDSH0eVPeNvbo6E6IysQgXC3ma6HRNS32EvE2zRERHPB7YZpHLohNC7lzWlj018VAsL0ipr5cPWh5Hx70/5SsjXlr6gO2+YPtR1Bhip+KdBEtl8+5qjH1zCWrrYwkhT7I4k0tW6yUbWfvLFY0J/PL5uXh82krc+PICjHz0k3j8thtSJOUhz/2r8+SyaEyg2nzh15puGHs1vRrjOofwQ13Xit2dZhFyl8fg1tcXxxvn+L3wOFw0JnCwPoqeY9/DoPs+wq7qOtTWxzBpyZYkVwoAPPj+CtTWx1C5t0Z7zdid+629npgQmL6iMh5WCgBPTl+FeWt3emYolNfSqV5AQsjVXobXUn06ljm7Vnzwiv2tqYuiYsy7eGzqN6Ee8/FpCTeBmxwW+ViURx2aCJGrjw9mKj5yJLr6z32+FoPvm+L5MDw+bZVPrQ3kO93KJTQQSDx0QVwN8uXw6kIKISzhibL8Afcm/IzxeGmXhubud5bhxdnr8PNnvkC/PxqLW9hfyG8cIoW+/0Rilu2yTXvw1oKNSUIYEwLvL9uKB99fgdnfGhkRvV5gINEw+r2o0ZiINyDSgrQf363HNXHxpriPvChk14rOkIb0y9vPUf0YjQlsVPzYu3xCbVdV7cNNLy/EoD995OiWcWL7fqtgxoTA2DeTJ45d9ORnOP3B6a7lyGfVzZaRBoJ6fZ0MEPn7yr3+kVmZyOdTMEI+eelmDL7vI9dFa+XD9Nznax2/T5WJixO5KNxeBL/3Q3W97K2pxz8/XmXxp8eEsNz8rXsOprzUm1opKZTf7XcYyluWJu0ikHhBg1gRdVGBrXtqkma0qtTHRNz/aJTvXA5g9DKckEL22SolUsR2sR/+MNndtVHx/76zaBNufHkhHrHt99jURAOtew3ky+w7a1eIuCBKIUkSRpffXjthgdJT8c6QuX3fwaQ49uSwPuVvjVssn9UFtiXT7K4VtXfq15Opq4/hXTOni86sVyA5Pj8mUrN06+KuFet1+WDZFtz8ysK4YaUKuZOPvH0L4/2R8eXRmHBNpZvq7FMvCkbI5eCJU9wwkBjNDjJhxs5P/jUL//x4FeqjMcdE90FnxvXt3BqANV76oQ9W4P73luOdhYkEPkIkRwKEMTtMTvHu1qE55owdnvR9NCbiL0eQAZr6qMDg+z7CL22RB/Z9DigDfWq0gTw39bo4+ZvLzIFKlcTtDXYvltvKV2djymvgN0FJHtHv3kRjIn49pcVnN0S9ypBjB2r4odP9GXDvFJxwz4eWbfbBcEvPT+MWS3eOmhLg4Q+/xm4lXDAWExYL12/wt1YRb79ej2T7PquQCyFSEvL4JbQ9LqOen4c35m+M9xDqooYw3/LqoqSGqXJPTdyl8tIXRujin99f7jrPgi1yB2TL53dt5Ivi5+YA3F+iz1Ztx/3vLcfv31mGgfdOQXVt1GJ5uAm5m+/8qqHdsGbc+ah2yJmhPvxCiKRW3ElTzj6mo+Xzq7862aEu5v8g1Ji+dBlLbcd4OeTx9B8+t1he9TLUxWKWgSFVyOQ1UF/qdYp18+WmPVhVtS8ecaJSUxfD5f+ejfSWR7YiT91vglIk7lrxLk8VcjeLXJZxy6uLcMl46+IFThb5ZZpZD+3PonpYnXtcYotd//DLrfjbR99YFjWujwnLu7BHWUja6VVQG3HdJe62O1rkWj+1IBtDt3e3TnGtjHljMV6dtyEeAiwZbzx4MuIAACAASURBVMa3A0ATs8fi5hmQdQ2bvBfyByYbLZ/sfrsNWtTFLXL/U/azPicvNWb22Ueo3QxyvxHx6trkrqd1QpCeD9W+7cSKdsnHVCopLfJmLkKuWuRBpssfcDgfO/VRYXmgVfGvt4kcAFzz3Ny4sJ/3t09w1l8+jkec2Pnkm22hrnkpr6vfhK6Ipo+8PiriDZMUCjfXyqvzNmDWauuqRXVyHEVprJxSATjX0fpZdZFoCXlxooBfvTAPH39dmbSP/f1RjRKnV0FtsHVn89onDMWESCkjpbTr3N7duI9cJBqnmjr3OkqXmZsOAZlxreR9rpXpK4wHaXe1d/et3mGASHLlM1/gO/0OS+wbEyh21jYLAlb/n/vNc94uLaoDDrHE9RYh97fI7ed1UvdkEVfL/eSbqnj+k1KXk52/bhdem2d0Ff1ETK3fM5+u8dzXKM8993ttNIaykqKkF3PfwXq0K07kd/FqcMOMDNCdbCLFwO9a/XPG6rhrTkbQ2Iv2etnr4rHT5ucAqQxkQ37zKwsx4+sqSwOgoy+qIfSBy0zdeqXHARizg71Q66/rWtlVbbfIU0t3vHl3Da585gvXeH5pANbWx+K9mS8V960Q1kn6+2ujriGIMp8Lx5E7YBdot5a11mEShWTaiirc/Mqi+GfdC/3mgo2WLn9Q97ts4Z18veoDHRPJFrF8fIYfbbhTSosjtskd3pWp3HswbuWXuLibHpi8HKuqjNCtDTu9Zyuq8bv2tK1O1EZjri9evYuV+vbCjZi8NDG47NVLkBOrVILkulGJTzaJeouFvOZTvtrqOQ1fHV+R1nWQXC9S+ORPnAwBN6QYvTF/I7Y5+Jn9f+9/jH98vMrSg1RdK06oA5w6obMAsM+WUVKkONi5eXcNpq2ocu3ByV5rTV00/n7LMFvAufFzK0teukz4yPPeIpcC4je5pdac7q0zIDlnzQ4M632I73721VNco1Z8DtnGIfyv3jYjKCk8zvy6a3tjxmVRhCyWge60diDh1/Nijc+0cx1LSu2x2F0rKnEr1fb9H/73peVzNGCmu+EPf4wZt5wR6DeA1UfuFVUh7/Ozn61xzfZoJx6qabu/ew/W4fqXFjj+RvY+pfC6WZNOeD0WizaEt3qNamVXKxbqjgPeLiBdY3W/7ZwXrt+VkfUzZcNysD7mqh32wIcvN+1J6iVV7q1JjDexRZ6MfJnlpbEP5jw+bSUqxryL6lr9WYI/f2aO1rHtLa/rYKfL72Wdrz+rZ9J39Zbww+SbL60PKdgRosB5M6R46OZn8UInbEytUn0s5mpB1boMANrRtd5UdOJ87dQrkQs1HsdU77+u9V8fFbhv0leYb1sKcOnGPa5Lj00yx2jk1dmvMSbhVMdU0BWhNdsSk3BUV8Mb84Pn7HHigC1y5DqXRi9d1MU73BpBu7/+0n/NSoqCkjmLAB7sdER2Td26onLCjvTTqZaqEALvLtZbk9AJu5C4iafcbLd85UtxWq9yS75iwGrRxIRIOj8ZCy1fzKKIdWq+jptHWvVurpUgBE05WxcVrgN0shHz6+p/tTn4ijbLNgVfpSXuI4/GsNNjUFG9/bprVx6sj2L8jNVJSaK8kL0feX2c4rTdBLcoQpb4/aDUaarQr15ILBFXnYF1PDe55DVyY6Et7l0X9R13e791UnCoRgn7yB2o97HepHDLh1cNn5q2ohKjJ+itSaiKijxmskVulru8EhVj3sViM+m9dCnYw/K87qc6q1Eg+fxkjLZ8hiJkT0mqYZHHpI88/cdgkuYivZL6qMBvXNaDlBaw3/O+YmtwIU9HxOpjwtH3LlGv+U4fF4JEdwKME/L6fL7KWichhLufloAzHpqe8jF1UvDaOegR5dFQfO/xT1P6nRqh8qHL4K6OMKue0pydok9EI4hoBRGtJKIxYZSpi33mlV2+im1CrkYfrqrUX6hWvVlyssham99YvsdXPmu4ZuSMQzdN9Rr0qKmLoThCKIoQFq3fhbm2rrdExsGSzbWiY5EnBjvTfwz+pcTS6uC1Sk5tvfMAYBg8+H5ywi5d6qIxx9DKijHvWgbDACPiJ9PIq7PZZp1u2u2eb2fi4s2BMvXZeWVu8LVXdXsnucgHX/ovIqITmqs27DlpkRNREYDHAYwEcAyAS4nomHTL1UV2w+XFtIum9P/KUW41fGrbfv0HWudm2a3gV+asRzQm3H3kPkLVpDgCIqNBcMtXIQd57cI9qJtz+KFKLG6Rp+9a0bk+6lHqPAZH99TU4dOV2zLiS0yHuqhwPc/LnpptTRXQAEjfrD0s8vY3lqRl6YeN17hCQ5HqjO45a5wNKBWdHOhqjvNctcgHAVgphFgthKgF8F8AF4ZQriOjJ8zHtaY7pGrvwbj/LeZjkcuBI9VHbg9h8kLn4tt9aKu37ccvn5/n6lvzK7OkKIJDWpZ57iNPJ0IUL++eC/vgGnNNQy/CtMiDrq9Z4yHkt7y2CJc9NRtrt+n3mBqCUc/PdXUtzFu7M9RJSDosXL8L89buTIpb//jrKjyURs8jbIJE1agM6+2y8GcKZHKd8aDrhOaqkB8OQF0baYO5zQIRjSKiuUQ0t6qqyv61Nu8u3hxPVDX0gUTOZDc3hbSSZRY8tWUOcnP1LHLg5TnWhPtTvtpqSdKk4teQNymOYEiP9p77HKhLhFXKS9CtQ4ukxqOiffLCEGH6yIMOdnpNElm/w7he9mnY2UaI9HzamWDBup2OKRFeti1X1hAM6NrWcbvTTMiWpf6RzzqzsHVJ575179Dc8/ugRkwaS9G60mCDnUKI8UKIgUKIgeXl4bS0qgUUt8htAmYPN1Qtcq9ptEmJ/rVcB4Tfvb7Edz8AGNi1Lc7u09FznyZFEcfJQioyDEvOGpN/2/ngptOx/J4Rlm3ynOQ1GlTRDkOP7KBT/SSCWiV+k0QA/bwbDcmjH4WbBjldDiq52HOVLx0W5dAxonQW82gIWpRZG51OrcsseX7muYxfuZGTPnIAGwF0UT53NreFjpdP2c0it/vGVGH3cpups7cATR9wAAv/tV8PQasy70kjG3dV+wr5voOKRe6RKKpJcXKjYHetvPKrkzHuouN86+6Em59w2R/Ojf+tXkKdBXpTiRMPg9LiiGv+mVzjYF1Ue53KTEMA/n7p8b77vXPtKVrzHNx6sg2N/VmIEKFXxxYpl5errpU5AHoSUTciagLgEgDvhFBuEmpLZp/YIRPZJw122rpntfWx+IohXg+TXHJN8v0n/MOX0lmF3A2nDH8q3cuNbl9RhDwtcifk5VQHO93yrqj8+aK+eOTH/Szb3LquzZUutCo49kkUTmTLIi+OUPy65joHfWabhkWXdk199yGCJWeREx1aNEHfzm20ntHbRh6lW72M0sLmBnrkx/3x0MX9cGF/73N1IyeFXAhRD+BaAO8D+ArAK0KIZd6/Sg3VKr7mOesECjk91/582KeqT/mq0nPFEIndlSL9tl7oWBle3P2d5GCfshL3W3TnBcfgrKMPMY+dsBx0fd5x14rS2HkdT9KyrBinpOCCUQXnien+qxilM1krHQ5tXWbJ9d0QPHHZCbh4QOfAvztYF4uPT4w+o4fjAiFhcKZGygod5JiVjkh3dRjXSQW3LJm6NGtiFfJB3dqhZ8eWuGJIRUrl5aprBUKISUKIXkKIHkKIP4VRphNqS1bltqwbEd5ftgWXjp8FwD20TggR+ki2ziSc//xiEG45t7fjd04NgT1X+Ce3JnKFXDW0W9zPHyHCn3/YDzec1RMDjnAedLLzlx/1w5GHtAhskRORr1vICd1lvLJN70Nbai02HSZFEUrpedxdXYfpK6rQq2ML3HLuUfjdiGSBDOM510nj4DXmJJHvyI9PPEJ733RpnqabrLnLwGyJS2N/TKdWnuXphAYHJa+SZqktmVebdt2EBag1V/GxLzYriQnvFVHkV2GsxKNySo/2OL2X82Cv07HKbMLapV0zPP6TE+JWhvSLRwgob1mKm87upV2XC/sfjgv7WwOMdGLKI+ScsdGPoKP72aJJUSTUiAkdSorIVbhKiyOubqY3FxjDUV9v3Rcvx87Nw3vhLw5L3gXBK0fR7ecdhfsmua9Yr6KTzC2Vfb1o1qQ4rYRabg2BW/1KfXq1dgs/DPJqir5Ol4RgLF0GGImL3CYC1MdinoNE8lDdbpuEW5Vgfif6mUu2eQ02SrwsG6dflykP0f+uHQoAOL9vp/hqQPIUwrJe3NxD1595ZPxv+QA/cdkJruW0aVaCe793rGVbrkdXSIoikdBERBch3K/9D07Qd7k4ZbIsSdO14FaupEtb0wWS4iV74arBAJIFM6x70Lw0PYu8XYsmjtvdjB6dbKJhk7dC7jVgIG9c1d6Drqt59L5jMr7Z6p6hTrWOX53nPi15+v8Nw9M/P9H8jetuWth//9I1J6HMfAn7d2mD48wGQ0VeBzcRePrnA/HKL5OXfAuMw5J25x3XCT1cBgVP7VmOn57U1bItlTwd2aCkiLSyZKbC4W0Sg4ZqLHVdVLgOlrcq07fgnMZHwhAWL1GVvd5SjQbDqdfZ04wAuXSQ1d0SnpCnbgGfWNEWPcqdI1Tc3rlMPTte5JeQ21aSd4IoITTXvbQASza651j2iv+sqYtqTXJpWVaMVmbu6bDdMIO6tYu7MNx6D/KQbs/8mUd1DOyTc+pKquWrz69bJ8npWmTCtfLHC/uEUg4R8HNz8KrIzHEDGLNkH/lxP5zc3XtilhvqmIY8jmTs+UfH/66Puee7DiIMTtb3kYckC5FfdIkdr3z/leZ4ldpIueH0CJS3KMWacefjxyd2sWz3W2NAl+ZpuDJO6t7es1fvhM5YQdjklZDrjJUR3H2NdryiO2rqYlrJfoojkfjxdCJbvLA/4xFKDHa6uSXsecnDYPbY4UnbIg4WOeC+3qcTmRDyn51cEe+a63KIQ2TH3d/pE5/9WhyhuIiUlRTh+8d3xuerU8ujYo+YkCs6AbbFqKMx18Y4yMzbEodCejrEPKtugam/PT3+t1vUi9tYEwAc17kNAOB7xydN6E7Cab5HfEFw23ub6jNtv+bpzAkYdVp313q4vZOZTAfgRl4Jue7EB90L6ZUn+bFpK5OWwnKiqIjiL2C606LtzwsRxQc73XoHfq6VVPCzyFUhH/+zgdrlBp3GrzLt/4a5fje0p34o5KBu7XDc4ckuKqJEQ6P6yNMde7C7NX57TmIwWm3X6qMirXzX0mp0ssidhEiNuOiuuA5O6+k8EO91Hfp3aYNV952Hkxx6LeeYYzmdWhs5g5x6avK87fVMRcg/+u3plvEcID3XSsuyEsvA90MXJ+ZPHN2pFUb0OTTlssMkr4RcR8djymrXdnTeyb8pM9N08jYXRyg0Eb3kxCOS/IRNmxi3yM2ajfm4VuzIF8sLp/NRt6kBHTrd6dd/bfjo3QardererUNznHmUXizzPR7uFrcB2g4tSuPXuLiI4uLpJCbv3XCqVj2AZOtQFWX1elzQ9zDX51NH0D677cyk8iUtSouT/OxFbmG5LgP2flVQ6zhYceXJ7b0PbQnAO3+K/RhevQA3epS3SBprcouw0s2IqJ7bD5VY/6IIpTwTOmzySsh1Fi0VQiCdyDG/mZR2/BZ9DnTsJkW4/wfWB0PGdfu5VnQtx8c9Ik28UIsPaqUe38WIa3ebgagbyvjvKwbi4gGdMeEaw5XSua1zI+JW3lujT0GHFsmugycvOwEjjz00LqzFEYq7HuS2CVcPxjGdWuHTMWfiaJ84YRW7kKviIa3Tn550BJo2KXK9rn4WefcOzeNZMlWXyfFHtMHs289CsybFmH37cIu/3lXEXF4xt8bk7dGnJG174erB8f07tjLqJXsmXpNz7OcfNPXs3DsMl6BdJ9xcKzqDs0BijMLp9qjXRQ5eh9k71iW/hFzDJH957npsd3GJ6IxFBn14EvnA/X83qCL4RAD5Eru5JWRmNt1ZZqlmOlQHcLzO9QEHC0Xu7nb/dBtPIsKDF/fDkB4dMGfscLx/42mO+5W6lHdYmzJLfSQjj+sEIoq/2C3KitHMfClldskhR3bApBtO1eqBqKjPk1woRCIbCXk93a5qkHzxqivnzd+cEhfSpk2KLFPN3e6h+or8cEDneP3dxKlflzYO9Y3g/RtPxRu/GRK/pk2KNYTc9u5FiPCMGRHmR0X7ZvFGWs5Y/vmQCjz3i0GWxc27lzfHf0edZNTToS6HtCxNmt0s71m7ZslhiOr9nH7LMDQtKcLoYT0s+5zft5PWOaRDngm5/z5LN+5JWvhUotNQBg0dkg+fn/4P7NoW//nFoEBlA4nBTrcQqPbmiP93A0YhBMXqI3ffr6lDhACRIWCVLivTpDK5qLxlqavvs0lRspUE+EdBXH5yV9xybm9cNbRbXPTsi/wGRRXARXedY/kcjbvFzGfI5cIG8RV7NdSqO8XtUtw28ii0aVaCts1K8NDF/eIhpEG9HEce0hInKDOMZQPhFQppvz9FEcIZijvtKNM9o3KHGfmj5u2XFnn75k1wWq9yi2AfWd4ibvw4zYD+YuxwtG9u7bUdMBPTHeswtqLem/YtSvHVPSMw2DZWYJ/UlwnydmZnUMZfPgC/eXE+6n3M8lRHyo0X1L3sI9o1S5pur0PrpiV44arBjgN0qXKBMqFIF9WCS6Xr2KtjS0xf4ZyH3m8mXFBUP6yXS2j0GT3wPWVma2lxEUafYQyUyV7C/hQXRXDC3vD072LcU5lz3u2y+vWi1KfOa/KP2jv44tsdjvsc0qoMc8YODy+AzixIirSbOwxIbizsvePjDm+dZKQNNHu56oC3NPhkw6g2HtV1URzSqgxvjT4FXds1w/H3fAgAePHqwfHG2z5HZWBFW1w2+AjcODx51rROiGSqqxMFoVEIed/OrXFOn0PNF9m7jFSnZtvvVdtmJZZpwen4zYJEZejw2E+C+8nViAR7Yzf6jB54fJp3Eqx2zd1zs5zWsxyrq8JbDUgVM7Wudou3X+c26Nkx2coDEpPKqh3W6AzKZYOPSEoyNqiiHQZ0bYdFd52D1mbXXzY05/bpiNvPOxqnPzgd5/bpGMi14rWvei2uObU7bnx5oUsZ4TWs0iXX+9CWeODI4zDi2ISb4eaze8WjWQAH14rts9Ob279LG7w1+hT0VQwde0iu+jzcZSam69+ljSW8WL0/9sCCspIi/On7zoOaOoafztheuuSXkKd4QeRAoY6WFpkpTP2E5dYR1sRX9kkAI4/rhAmzE6sFZSO2NEyO69waLcuKsbemPqnR6mvGEau+Rfud2n/Q3bK96exeePazNSHV1CpmLcsSDWqi3v43Qw5odndxafkx5ebT44OZdhGYd8dwtDSTjrVW/Ld9DjOOedEJndG1fXN8e/95ANxXb3fCLZETYDVS7G6CV355smPmS7n6UKoZBNXn3p4o6/qzelo+23tMuhOC+tv89NLgk7+XsfU/GtgZRx6SaLjdxgmkj13HP+9moB3epmk8n/phrb2XawyDPPORpybkcqDQa5BOvuTFEcKTlw3wLXNg13b4zbBEvKpd3GpsXfIwrZxsIU/Rfh2lcHoNWnr5RsNY/NntWC9enZgsFMRtdmrPcrx3w6m4xDbb0M6q+85z3N65bVNXa799i1JHYbyg72GYcvNpOMeMTSYyQlvVSUROqLHZXq4V9fTtERuDurWLN8gqB80UF6lO85eH1Jn17OQjt/PMlSfimSu9BTY+iCzHr8z/7ZFfbo/DmJFHIULp9YSn3zIMX987EuMvH4DrbA1WJsgrdVld5Z4bxQv5fKgPhn1wsFiJG9YZ8LQ/13Zf6gHb56BhjbmAXWD3mItV2329spHyPEePSxohSkqwlQ5HtEvkse6i/B00bPLoTq18XWJujUOqE4lUizFeVoTwy9PdF9O+Wllo26tRVM+ltCSC534xCBOvG+pZH7lKkz0S6NBWelamPKROZ5ps75T92goBnNH7EJzhkxtdxENyjc8yUKCDbdaq2727eGAXrL7//LSMr5KiCJoUR3BOn0MbxIjLK9fKP2esTul30u2hvlv2i1scIdTCPWrl0kFHoGlJEZ7+9FuzLPcX5qhDW+L6s3qiV8cW+NvUlQASE3vyhYW/PxtFEcJxd3+Q9J09BE++EC3Kil31+shDWrgOsEWILJNI0uGrP45wHVSOh/lJcUnjOEcd2tIxOipCxiStsMe33PJ3fHv/eZZn0cu1olJaXITTXNIpq9TWO1vk7994mparU9Zb51rrWOQ6RG0+8gFd22LCNYPRp5PVndSQ8d6PXtIfD3/4NX5jC00Mi7wS8k6ty7Cy0rDKB1W0wxdrnIXBjpNFXlJElpfREPYoiiMRx5dhYNe2GHHsoXEh97K4Jpvxzccc1gqTl23B11v35Z1F3sYhZvbiAZ3x6rwNSW4BuWzbsYe3jucxsYdL/v6CYyxjBioRCu+l8ooMik/eMj+nMwb1+q+HYJ8tNPH/zumF03qV493Fm0NPg+t2eezXTXc2pO5kGOkjLy2J4PzjOmHOmh2YddtZ2scJclvt71SqvZqoQ2rnIT3CDRgIilPu/zDJKzOxon0iZerxRyT789yQA1dqi19cRHHBBRJd0uII4Yj2zZKmeXdqU2Z5Od0GYpIWezYbhVRipXONBy/uhzXjzk/aPqz3IRh1Wnfc9Z0+GNy9PSZcMzgp34XX+UeIQg/RevHqwXjwh31txzH+TyyJl/oxm5cWxyfbSK49syf6dm6D2847OnRrT5Y26rTu+MdPU5udq6Ir5NJHXloUweOXnYAvxg5Paeq8TqNpt5/sh9HttX2nnxEZ45T7pVDJK4v81hG9MXV5JTbuqkYfZdT9ssGG2+Opmd8m/ebSQV1w5wVGyJH6cv1kkDVXthRcucvlJ1fgzreNpUefvfJEDOnRwbKqu+57KmOkC0HI3SgrKcLt5yVSsga1foisLq0xI4/CuPf0VpyRdO/QHKu3JSKNnNYUlff/7u/2QUWH5r6+1lxCPm8tS4stIXypl6f3ACd85GkOdmo4V+wWuIxt+N+1Q7Gnpi4eb+/HkB4dHA2OQiavhLxlWQk+HWMkB1qwLpFLvFuH5rhqaDdHIT+5R4f40kqyhf/8tjPRqbXVzyuFxMlyGGa+8KoV7mZh2DdLyyeIa+WO84/WyrzYEIy/fEA8jCpsJlw9GK/P3wgisoxZ/Or0HoGFfOL1Q1GtOXmnTbMmjpM7cpkgvuYw+d2Io/DbVxcFyi9jgdzfKzv2Xq6M5XdaUIWxkldCrqJauF4ZCNWwJ9niO0UxSreJ1/OmWgxeKxSpyDjhIBa5GoWQbc7JYJrOIUd2wBDTck7XtdKsSXFG1kLMFYJEfzQpjoSWsmFw9/aY+bszU/59wiLX2Fd5BJbfM8L3nTmxQm+R8Uzz7JUnBs7BEzZ5++RbhNxrHUzlCZJiHXNQ8i5tm2Ht9gOWgby3R5+Ctsqgn+obdBNye7zsZYO7Ysf+WpzUPfyVs/ONG4f3RJPiCAYc0Rbrd1qtfJ1V2hszQVwUX9870vW7t0ef4rp4RCa4ZFAXTFqy2TceH7C6e/xEfNHvz0FZSJFgI49Nz1gZlgMuurwV8qY2i9wN9cG//byjcetrixwf5Md+cjxmrtxmaVmdMrtJ7G3B678+GRc9+XnSa3Zar3KtMK/GgOrOsK/pE/akoIamXXPnBXrDYvgxHfG3qSu1c7K74fVMZ4JOrZviw5tP998xIK2buad8CMKKe0eknJYjl8hbIVenE7dqar2p91zYB09MX4XNu2ssFvn5fTslpZQ8uXt7fL56O9o0a4IL+up3R+2Wd4tSuW6ndhGMQj6/THPvGK4dBZIqfTu3aRQDeDec1RPDejec4VPaAJkJG4I8FvLEDZDLLR3dqRXO6F2Oy0+uwPx1u/Dmgo2+wvrsL070zANiR8av29MFhB033NjIZ4vcabEKJjVuOju/BqFzhbwVctUCkr5rdQku3UGW0uKiQK1yr0Nb4Is1O5J6ASzk6eE2WD3+8gENHqmRD9z/g+Mw85tt2a4GkyPkrZD7xsHGR/nDlYE7LzgGI4/tlBSO1RA5hxsjg7q1c5xl2ti5dFDy+q5M4yV/HZMmFyuLoarIFUNaloXbVpUWFzlONkllthvjTzbWP2SYfCNvLXIAnoM/N53dE906NMO5GYyDVtHNncwEI4z20T7rk2EKjbwWci9Ki4uSEtlnEvaRZ4Ywruv/rhuK/SGs9MMwuUrBCnlDw0KeGVLNgKfSvLTYdaFmhikE8t5HniuwayUz8GVlGH/YTAmJojyOg84Vju7UCifY0hOHYZEzTKHDQh4SbJGnjzoPQMJCzjD+sGslJNhHHi4yrJQvK8P4w0IeEizk4TLuor5Ycvc5HEfOMBqwkIcE63i4FEUILcvCyXDHMIUOC3lIsOXIMEy2SGuwk4juBnANgCpz0+1CiEnpVipfufOCY7TXFWQYhgmLMKJWHhFCPBRCOXnPVUO7ZbsKDMM0Qti1wjAMk+eEIeTXEtFiInqaiFxXQyWiUUQ0l4jmVlVVue3GMAzDBIT88nUT0RQATikExwKYBWAbjPUb7gHQSQjxC7+DDhw4UMydOzd4bRmGYRoxRDRPCDHQvt3XRy6EGK55gH8BmJhC3RiGYZg0SMu1QkTqSsbfB7A0veowDMMwQUk3auXPRNQfhmtlDYBfpl0jhmEYJhBpCbkQ4vKwKsIwDMOkBocfMgzD5Dm+USsZOShRFYC1Kf68A4xImcYEn3PjgM+5cZDOOXcVQpTbN2ZFyNOBiOY6hd8UMnzOjQM+58ZBJs6ZXSsMwzB5Dgs5wzBMnpOPQj4+2xXIAnzOjQM+58ZB6Oecdz5yhmEYxko+WuQMwzCMAgs5wzBMnpNXQk5EI4hoBRGtJKIx2a5PGBBRFyKaRkRfEtEyIrrB3N6OiD4kom/M/9ua24mI/mZeg8VEdEJ2zyB1iKiIiBYQ0UTzczcimm2e28tE1MTcXmp+g9qACAAAA7lJREFUXml+X5HNeqcKEbUhoteIaDkRfUVEJxf6fSaim8zneikRvUREZYV2n80U3pVEtFTZFvi+EtEV5v7fENEVQeqQN0JOREUAHgcwEsAxAC4lomOyW6tQqAfwWyHEMQBOAjDaPK8xAD4SQvQE8JH5GTDOv6f5bxSAJxu+yqFxA4CvlM8PwFhx6kgAOwFcZW6/CsBOc/sj5n75yKMAJgshjgLQD8a5F+x9JqLDAVwPYKAQ4lgARQAuQeHd52cBjLBtC3RfiagdgLsADAYwCMBdXus7JCGEyIt/AE4G8L7y+TYAt2W7Xhk4z7cBnA1gBYz87gDQCcAK8+9/ArhU2T++Xz79A9DZfMDPhJH+mGDMdiu2328A7wM42fy72NyPsn0OAc+3NYBv7fUu5PsM4HAA6wG0M+/bRADnFuJ9BlABYGmq9xXApQD+qWy37Of3L28sciQeCskGc1vBYHYljwcwG0BHIcRm86stADqafxfKdfgrgFsBxMzP7QHsEkLUm5/V84qfs/n9bnP/fKIbjEXKnzHdSU8RUXMU8H0WQmwE8BCAdQA2w7hv81DY91kS9L6mdb/zScgLGiJqAeB1ADcKIfao3wmjiS6YOFEiugBApRBiXrbr0oAUAzgBwJNCiOMB7Eeiuw2gIO9zWwAXwmjEDgPQHMkuiIKnIe5rPgn5RgBdlM+dzW15DxGVwBDxF4UQb5ibt8qFO8z/K83thXAdTgHwXSJaA+C/MNwrjwJoQ0QytbJ6XvFzNr9vDWB7Q1Y4BDYA2CCEmG1+fg2GsBfyfR4O4FshRJUQog7AGzDufSHfZ0nQ+5rW/c4nIZ8DoKc54t0ExqDJO1muU9oQEQH4N4CvhBAPK1+9A0COXF8Bw3cut//MHP0+CcBupQuXFwghbhNCdBZCVMC4j1OFEJcBmAbgh+Zu9nOW1+KH5v55ZbkKIbYAWE9Evc1NZwH4EgV8n2G4VE4iombmcy7PuWDvs0LQ+/o+gHOIqK3ZkznH3KZHtgcJAg4onAfgawCrAIzNdn1COqehMLpdiwEsNP+dB8M3+BGAbwBMAdDO3J9gRO+sArAERkRA1s8jjfMfBmCi+Xd3AF8AWAngVQCl5vYy8/NK8/vu2a53iufaH8Bc816/BaBtod9nAH8AsBzGMpDPAygttPsM4CUYYwB1MHpeV6VyXwH8wjz3lQCuDFIHnqLPMAyT5+STa4VhGIZxgIWcYRgmz2EhZxiGyXNYyBmGYfIcFnKGYZg8h4WcYRgmz2EhZxiGyXP+HyXhgqopKDMoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}